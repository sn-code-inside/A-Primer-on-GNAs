{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This jupyter notebook includes the preprocessing steps required to implement text to speech GAN model."
      ],
      "metadata": {
        "id": "Y6D96w3qNxWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Modules"
      ],
      "metadata": {
        "id": "hY1Cf1B0N-zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Import regular expressions module for processing text\n",
        "import re\n",
        "\n",
        "# Import the Natural Language Toolkit (nltk) for text processing\n",
        "import nltk\n",
        "import unicodedata\n",
        "from nltk.corpus import cmudict\n",
        "\n",
        "# Download the required datasets from nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('cmudict')\n",
        "\n",
        "# Import stopwords from nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Import NumPy for numerical computing\n",
        "import numpy as np\n",
        "import string\n",
        "\n",
        "import librosa\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d68CkGIwOBVJ",
        "outputId": "de337ef3-f032-4352-a3f2-1a92f675db8a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download data from kaggle"
      ],
      "metadata": {
        "id": "9lds1hNJ_NYx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U86BXv-v6bH",
        "outputId": "6e05c9d1-30b6-4cea-9ee7-b4d48799a9a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ljspeech-sr16k-dataset.zip to /content\n",
            "100% 2.18G/2.18G [01:41<00:00, 25.1MB/s]\n",
            "100% 2.18G/2.18G [01:41<00:00, 23.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "#steps found in \"https://www.kaggle.com/general/74235\"\n",
        "! pip install -q kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download showmik50/ljspeech-sr16k-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Td8HPSWqwktf"
      },
      "outputs": [],
      "source": [
        "!unzip -q \"/content/ljspeech-sr16k-dataset.zip\" -d \"/content/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Text Data"
      ],
      "metadata": {
        "id": "dOp2K2K5_Q_4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSw9gHnpwyN8",
        "outputId": "dd7ceb7e-f78d-4c25-dedc-4e1961de7540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('metadata.csv')\n",
        "print(df['sentence'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean text data"
      ],
      "metadata": {
        "id": "bxvBUMRvOTOs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-XkrzXjxIX6",
        "outputId": "8e256f4c-c630-4859-84ea-08ca68839b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "printing in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the exhibition.\n"
          ]
        }
      ],
      "source": [
        "def preprocess_text(text):\n",
        "    # remove punctuation from the text\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    \n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    return \" \".join(tokens) +'.'\n",
        "\n",
        "# Apply the processing function to captions column in the DataFrame\n",
        "df[\"preprocessed_sentences\"] = df[\"sentence\"].apply(preprocess_text)\n",
        "print(df['preprocessed_sentences'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Represent text by phonems"
      ],
      "metadata": {
        "id": "v4IAR-y3_YqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CMU Pronouncing Dictionary\n",
        "phonetics = cmudict.dict()\n",
        "\n",
        "# Define a function to convert text to phonemes\n",
        "def text_to_phonemes(text):\n",
        "  # Define an empty list to store word pronunciation\n",
        "  phonemes = []\n",
        "  # Enumerate over each word in the sentence\n",
        "  for word in text:\n",
        "    if word in phonetics:\n",
        "      # Convert each word to its list of phonemes \n",
        "      phonemes.extend(phonetics[word][0])\n",
        "  return phonemes"
      ],
      "metadata": {
        "id": "PXXyQBTh8UH4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Phonemes to numerical secuence"
      ],
      "metadata": {
        "id": "WoxB6tIJOvcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to convert phonemes to a numerical sequence\n",
        "def phonemes_to_sequence(phonemes):\n",
        "    # Define a mapping from phonemes to unique integers\n",
        "    all_phonems = []\n",
        "    \n",
        "    phoneme_set = set(all_pronounciations)\n",
        "    phoneme_to_int = {phoneme: i for i, phoneme in enumerate(phoneme_set)}\n",
        "    \n",
        "    # Convert each phoneme to its corresponding integer\n",
        "    sequence = [phoneme_to_int[phoneme] for phoneme in phonemes]\n",
        "    \n",
        "    return sequence"
      ],
      "metadata": {
        "id": "2sITAeIxOzU4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_pronounciation = df[\"preprocessed_sentences\"].apply(text_to_phonemes)\n",
        "all_pronounciations = []\n",
        "i = 0\n",
        "for u in word_pronounciation:\n",
        "  if i == 0:\n",
        "    all_pronounciations = u\n",
        "    i = i+1\n",
        "  else:\n",
        "    all_pronounciations.extend(u)\n",
        "numerical_representation = word_pronounciation.apply(phonemes_to_sequence)"
      ],
      "metadata": {
        "id": "VadUoTPfPAB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio"
      ],
      "metadata": {
        "id": "22bLKIvjJy_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Sampling Rate\n",
        "sr = 22050 \n",
        "# Define number of FFT points\n",
        "n_fft = 2048\n",
        "# Define number of samples between frames\n",
        "hop_length = 512 \n",
        "# Define number of Mel frequency bins\n",
        "n_mels = 128 \n",
        "# Load audio files and transform into mel-spectogram\n",
        "mel_spec_norm_all = []\n",
        "all_files = os.istdir('/content/wavs')\n",
        "for i in all_files:\n",
        "  audio, sr = librosa.load('/content/wavs'+i, sr=sr)\n",
        "  # Extract mel- spectogram\n",
        "  mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, S=None, n_fft=n_fft,, hop_length=hop_length, n_mels=n_mels,  fmax=sr/2)\n",
        "  # Convert the mel-spectogram to decibels\n",
        "  mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "  # Normalize between o and 1\n",
        "  mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min())\n"
      ],
      "metadata": {
        "id": "YI3uFSP4aNVv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
